{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "lecture02",
      "language": "python",
      "name": "lecture02"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.2"
    },
    "colab": {
      "name": "word2vec.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/luojie1024/TextClassification/blob/main/word2vec.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nsVty8_ooSPQ"
      },
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "import jieba"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "91lm3yrJoSPW"
      },
      "source": [
        "# 0. gensim实践：\n",
        "\n",
        "1. 读取预处理好的数据\n",
        "2. 训练\n",
        "3. 完事"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xohX5p5PqA4S"
      },
      "source": [
        "# 1. 下载数据集"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U3F_6dc-qHFW",
        "outputId": "22c3b4fc-f252-4f25-8494-217d673a3571"
      },
      "source": [
        "! wget https://storage.googleapis.com/cluebenchmark/tasks/tnews_public.zip\n",
        "! unzip tnews_public.zip"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-04-05 06:11:52--  https://storage.googleapis.com/cluebenchmark/tasks/tnews_public.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 172.217.214.128, 172.253.114.128, 108.177.121.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|172.217.214.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4689325 (4.5M) [application/zip]\n",
            "Saving to: ‘tnews_public.zip’\n",
            "\n",
            "\rtnews_public.zip      0%[                    ]       0  --.-KB/s               \rtnews_public.zip    100%[===================>]   4.47M  --.-KB/s    in 0.04s   \n",
            "\n",
            "2021-04-05 06:11:52 (100 MB/s) - ‘tnews_public.zip’ saved [4689325/4689325]\n",
            "\n",
            "Archive:  tnews_public.zip\n",
            "  inflating: train.json              \n",
            "  inflating: dev.json                \n",
            "  inflating: test.json               \n",
            "  inflating: labels.json             \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wkWzdXyKqTIE"
      },
      "source": [
        "## 1.1 预处理数据"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wFn6Gwu9smgq"
      },
      "source": [
        "def get_sentence(data_file):\n",
        "  # 读取数据集中的句子\n",
        "  f=open('train.json','r',encoding='utf-8')\n",
        "  reader = f.readlines()\n",
        "  sentence=[]\n",
        "  for line in reader:\n",
        "    line=json.loads(line.strip())\n",
        "    sentence.append(line['sentence'])\n",
        "  return sentence"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "crZAcL_zs-fW"
      },
      "source": [
        "# 读取句子语料\n",
        "train_sentence=get_sentence('train.json')\n",
        "test_sentence=get_sentence('test.json')\n",
        "dev_sentence=get_sentence('dev.json')"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZtvnPU2toSPX"
      },
      "source": [
        "# 2. 载入数据"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dakJhzKPtr3L"
      },
      "source": [
        "# 使用所有语料作为词向量训练语料\n",
        "train_data=train_sentence+test_sentence+dev_sentence"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gS1xii-dt3iD"
      },
      "source": [
        "%%time\n",
        "# 分词处理\n",
        "train_data=[list(jieba.cut(stentence)) for stentence in train_data]"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BBqwvzdyoSPY"
      },
      "source": [
        "# 3. 模型创建\n",
        "\n",
        "Gensim中 Word2Vec 模型的期望输入是进过分词的句子列表，即是某个二维数组。这里我们暂时使用 Python 内置的数组，不过其在输入数据集较大的情况下会占用大量的 RAM。Gensim 本身只是要求能够迭代的有序句子列表，因此在工程实践中我们可以使用自定义的生成器，只在内存中保存单条语句。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ut8oHJ33oSPY"
      },
      "source": [
        "## Word2Vec 参数\n",
        "+ min_count\n",
        "\n",
        "在不同大小的语料集中，我们对于基准词频的需求也是不一样的。譬如在较大的语料集中，我们希望忽略那些只出现过一两次的单词，这里我们就可以通过设置min_count参数进行控制。一般而言，合理的参数值会设置在0~100之间。\n",
        "\n",
        "+ size\n",
        "\n",
        "size参数主要是用来设置神经网络的层数，Word2Vec 中的默认值是设置为100层。更大的层次设置意味着更多的输入数据，不过也能提升整体的准确度，合理的设置范围为 10~数百。\n",
        "\n",
        "+ workers\n",
        "\n",
        "workers参数用于设置并发训练时候的线程数，不过仅当Cython安装的情况下才会起作用："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "u5N9mutooSPY"
      },
      "source": [
        "# 引入 word2vec\n",
        "from gensim.models.word2vec import LineSentence\n",
        "from gensim.models import word2vec\n",
        "import gensim\n",
        "\n",
        "# 引入日志配置\n",
        "import logging\n",
        "\n",
        "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tLYeikE5oSPZ"
      },
      "source": [
        "# 构建训练"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aAWmSnGax3Xc"
      },
      "source": [
        "## FastText"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dqbCqrCqxxGW"
      },
      "source": [
        "from gensim.models import FastText"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H2mZIENAx9Sw",
        "outputId": "6db9790a-8103-4ece-9771-4943980c0bf2"
      },
      "source": [
        "model = FastText(train_data,  size=4, window=3, min_count=1, iter=10,min_n = 3 , max_n = 6,word_ngrams = 0)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-04-05 06:45:58,867 : INFO : collecting all words and their counts\n",
            "2021-04-05 06:45:58,876 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
            "2021-04-05 06:45:58,915 : INFO : PROGRESS: at sentence #10000, processed 129141 words, keeping 25698 word types\n",
            "2021-04-05 06:45:58,957 : INFO : PROGRESS: at sentence #20000, processed 258779 words, keeping 39123 word types\n",
            "2021-04-05 06:45:58,999 : INFO : PROGRESS: at sentence #30000, processed 387255 words, keeping 49324 word types\n",
            "2021-04-05 06:45:59,039 : INFO : PROGRESS: at sentence #40000, processed 515598 words, keeping 57864 word types\n",
            "2021-04-05 06:45:59,080 : INFO : PROGRESS: at sentence #50000, processed 644895 words, keeping 65382 word types\n",
            "2021-04-05 06:45:59,122 : INFO : PROGRESS: at sentence #60000, processed 774201 words, keeping 67815 word types\n",
            "2021-04-05 06:45:59,172 : INFO : PROGRESS: at sentence #70000, processed 903891 words, keeping 67815 word types\n",
            "2021-04-05 06:45:59,220 : INFO : PROGRESS: at sentence #80000, processed 1032613 words, keeping 67815 word types\n",
            "2021-04-05 06:45:59,262 : INFO : PROGRESS: at sentence #90000, processed 1161529 words, keeping 67815 word types\n",
            "2021-04-05 06:45:59,305 : INFO : PROGRESS: at sentence #100000, processed 1289998 words, keeping 67815 word types\n",
            "2021-04-05 06:45:59,345 : INFO : PROGRESS: at sentence #110000, processed 1419372 words, keeping 67815 word types\n",
            "2021-04-05 06:45:59,384 : INFO : PROGRESS: at sentence #120000, processed 1548930 words, keeping 67815 word types\n",
            "2021-04-05 06:45:59,426 : INFO : PROGRESS: at sentence #130000, processed 1678029 words, keeping 67815 word types\n",
            "2021-04-05 06:45:59,476 : INFO : PROGRESS: at sentence #140000, processed 1807295 words, keeping 67815 word types\n",
            "2021-04-05 06:45:59,518 : INFO : PROGRESS: at sentence #150000, processed 1935386 words, keeping 67815 word types\n",
            "2021-04-05 06:45:59,560 : INFO : PROGRESS: at sentence #160000, processed 2064737 words, keeping 67815 word types\n",
            "2021-04-05 06:45:59,562 : INFO : collected 67815 word types from a corpus of 2065815 raw words and 160080 sentences\n",
            "2021-04-05 06:45:59,565 : INFO : Loading a fresh vocabulary\n",
            "2021-04-05 06:45:59,950 : INFO : effective_min_count=1 retains 67815 unique words (100% of original 67815, drops 0)\n",
            "2021-04-05 06:45:59,951 : INFO : effective_min_count=1 leaves 2065815 word corpus (100% of original 2065815, drops 0)\n",
            "2021-04-05 06:46:00,203 : INFO : deleting the raw counts dictionary of 67815 items\n",
            "2021-04-05 06:46:00,211 : INFO : sample=0.001 downsamples 27 most-common words\n",
            "2021-04-05 06:46:00,213 : INFO : downsampling leaves estimated 1743150 word corpus (84.4% of prior 2065815)\n",
            "2021-04-05 06:46:00,460 : INFO : estimated required memory for 67815 words, 2000000 buckets and 4 dimensions: 36077580 bytes\n",
            "2021-04-05 06:46:00,462 : INFO : resetting layer weights\n",
            "2021-04-05 06:46:16,796 : INFO : Total number of ngrams is 262734\n",
            "2021-04-05 06:46:18,541 : INFO : training model with 3 workers on 67815 vocabulary and 4 features, using sg=0 hs=0 sample=0.001 negative=5 window=3\n",
            "2021-04-05 06:46:19,562 : INFO : EPOCH 1 - PROGRESS: at 24.21% examples, 417997 words/s, in_qsize 5, out_qsize 0\n",
            "2021-04-05 06:46:20,587 : INFO : EPOCH 1 - PROGRESS: at 48.84% examples, 418707 words/s, in_qsize 6, out_qsize 2\n",
            "2021-04-05 06:46:21,600 : INFO : EPOCH 1 - PROGRESS: at 74.49% examples, 426246 words/s, in_qsize 5, out_qsize 0\n",
            "2021-04-05 06:46:22,585 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2021-04-05 06:46:22,604 : INFO : EPOCH 1 - PROGRESS: at 99.52% examples, 428240 words/s, in_qsize 1, out_qsize 1\n",
            "2021-04-05 06:46:22,606 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2021-04-05 06:46:22,612 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2021-04-05 06:46:22,613 : INFO : EPOCH - 1 : training on 2065815 raw words (1743092 effective words) took 4.1s, 429270 effective words/s\n",
            "2021-04-05 06:46:23,636 : INFO : EPOCH 2 - PROGRESS: at 24.22% examples, 416968 words/s, in_qsize 4, out_qsize 1\n",
            "2021-04-05 06:46:24,656 : INFO : EPOCH 2 - PROGRESS: at 50.30% examples, 432263 words/s, in_qsize 5, out_qsize 2\n",
            "2021-04-05 06:46:25,669 : INFO : EPOCH 2 - PROGRESS: at 76.41% examples, 437578 words/s, in_qsize 5, out_qsize 0\n",
            "2021-04-05 06:46:26,545 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2021-04-05 06:46:26,564 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2021-04-05 06:46:26,567 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2021-04-05 06:46:26,570 : INFO : EPOCH - 2 : training on 2065815 raw words (1742925 effective words) took 3.9s, 441753 effective words/s\n",
            "2021-04-05 06:46:27,623 : INFO : EPOCH 3 - PROGRESS: at 25.67% examples, 429761 words/s, in_qsize 4, out_qsize 1\n",
            "2021-04-05 06:46:28,626 : INFO : EPOCH 3 - PROGRESS: at 49.82% examples, 425257 words/s, in_qsize 5, out_qsize 1\n",
            "2021-04-05 06:46:29,652 : INFO : EPOCH 3 - PROGRESS: at 75.46% examples, 428711 words/s, in_qsize 5, out_qsize 0\n",
            "2021-04-05 06:46:30,591 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2021-04-05 06:46:30,612 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2021-04-05 06:46:30,617 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2021-04-05 06:46:30,618 : INFO : EPOCH - 3 : training on 2065815 raw words (1743446 effective words) took 4.0s, 431997 effective words/s\n",
            "2021-04-05 06:46:31,639 : INFO : EPOCH 4 - PROGRESS: at 24.21% examples, 418077 words/s, in_qsize 5, out_qsize 0\n",
            "2021-04-05 06:46:32,693 : INFO : EPOCH 4 - PROGRESS: at 50.30% examples, 424994 words/s, in_qsize 3, out_qsize 2\n",
            "2021-04-05 06:46:33,709 : INFO : EPOCH 4 - PROGRESS: at 74.98% examples, 424569 words/s, in_qsize 6, out_qsize 2\n",
            "2021-04-05 06:46:34,634 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2021-04-05 06:46:34,652 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2021-04-05 06:46:34,658 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2021-04-05 06:46:34,661 : INFO : EPOCH - 4 : training on 2065815 raw words (1743324 effective words) took 4.0s, 432527 effective words/s\n",
            "2021-04-05 06:46:35,696 : INFO : EPOCH 5 - PROGRESS: at 24.71% examples, 420822 words/s, in_qsize 6, out_qsize 2\n",
            "2021-04-05 06:46:36,721 : INFO : EPOCH 5 - PROGRESS: at 50.79% examples, 432492 words/s, in_qsize 5, out_qsize 0\n",
            "2021-04-05 06:46:37,723 : INFO : EPOCH 5 - PROGRESS: at 76.41% examples, 437076 words/s, in_qsize 5, out_qsize 0\n",
            "2021-04-05 06:46:38,645 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2021-04-05 06:46:38,654 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2021-04-05 06:46:38,662 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2021-04-05 06:46:38,664 : INFO : EPOCH - 5 : training on 2065815 raw words (1743720 effective words) took 4.0s, 436968 effective words/s\n",
            "2021-04-05 06:46:39,701 : INFO : EPOCH 6 - PROGRESS: at 25.18% examples, 427062 words/s, in_qsize 5, out_qsize 0\n",
            "2021-04-05 06:46:40,728 : INFO : EPOCH 6 - PROGRESS: at 51.28% examples, 435073 words/s, in_qsize 5, out_qsize 0\n",
            "2021-04-05 06:46:41,749 : INFO : EPOCH 6 - PROGRESS: at 76.90% examples, 435923 words/s, in_qsize 6, out_qsize 1\n",
            "2021-04-05 06:46:42,607 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2021-04-05 06:46:42,609 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2021-04-05 06:46:42,611 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2021-04-05 06:46:42,616 : INFO : EPOCH - 6 : training on 2065815 raw words (1742773 effective words) took 3.9s, 442165 effective words/s\n",
            "2021-04-05 06:46:43,660 : INFO : EPOCH 7 - PROGRESS: at 24.69% examples, 416855 words/s, in_qsize 5, out_qsize 0\n",
            "2021-04-05 06:46:44,681 : INFO : EPOCH 7 - PROGRESS: at 49.34% examples, 419019 words/s, in_qsize 4, out_qsize 1\n",
            "2021-04-05 06:46:45,698 : INFO : EPOCH 7 - PROGRESS: at 74.49% examples, 422994 words/s, in_qsize 5, out_qsize 0\n",
            "2021-04-05 06:46:46,704 : INFO : EPOCH 7 - PROGRESS: at 98.70% examples, 422111 words/s, in_qsize 3, out_qsize 0\n",
            "2021-04-05 06:46:46,712 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2021-04-05 06:46:46,734 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2021-04-05 06:46:46,737 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2021-04-05 06:46:46,738 : INFO : EPOCH - 7 : training on 2065815 raw words (1743075 effective words) took 4.1s, 424059 effective words/s\n",
            "2021-04-05 06:46:47,779 : INFO : EPOCH 8 - PROGRESS: at 25.18% examples, 427566 words/s, in_qsize 5, out_qsize 0\n",
            "2021-04-05 06:46:48,799 : INFO : EPOCH 8 - PROGRESS: at 49.82% examples, 424673 words/s, in_qsize 6, out_qsize 2\n",
            "2021-04-05 06:46:49,825 : INFO : EPOCH 8 - PROGRESS: at 75.94% examples, 431209 words/s, in_qsize 5, out_qsize 0\n",
            "2021-04-05 06:46:50,744 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2021-04-05 06:46:50,759 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2021-04-05 06:46:50,764 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2021-04-05 06:46:50,766 : INFO : EPOCH - 8 : training on 2065815 raw words (1743781 effective words) took 4.0s, 434573 effective words/s\n",
            "2021-04-05 06:46:51,779 : INFO : EPOCH 9 - PROGRESS: at 24.71% examples, 428861 words/s, in_qsize 5, out_qsize 0\n",
            "2021-04-05 06:46:52,779 : INFO : EPOCH 9 - PROGRESS: at 49.32% examples, 429418 words/s, in_qsize 6, out_qsize 1\n",
            "2021-04-05 06:46:53,798 : INFO : EPOCH 9 - PROGRESS: at 74.01% examples, 426946 words/s, in_qsize 6, out_qsize 1\n",
            "2021-04-05 06:46:54,803 : INFO : EPOCH 9 - PROGRESS: at 98.70% examples, 427156 words/s, in_qsize 3, out_qsize 0\n",
            "2021-04-05 06:46:54,818 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2021-04-05 06:46:54,834 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2021-04-05 06:46:54,836 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2021-04-05 06:46:54,840 : INFO : EPOCH - 9 : training on 2065815 raw words (1743171 effective words) took 4.1s, 428840 effective words/s\n",
            "2021-04-05 06:46:55,881 : INFO : EPOCH 10 - PROGRESS: at 24.71% examples, 418563 words/s, in_qsize 5, out_qsize 0\n",
            "2021-04-05 06:46:56,903 : INFO : EPOCH 10 - PROGRESS: at 50.31% examples, 427995 words/s, in_qsize 5, out_qsize 0\n",
            "2021-04-05 06:46:57,911 : INFO : EPOCH 10 - PROGRESS: at 75.93% examples, 433115 words/s, in_qsize 5, out_qsize 0\n",
            "2021-04-05 06:46:58,832 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2021-04-05 06:46:58,853 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2021-04-05 06:46:58,854 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2021-04-05 06:46:58,855 : INFO : EPOCH - 10 : training on 2065815 raw words (1743068 effective words) took 4.0s, 435633 effective words/s\n",
            "2021-04-05 06:46:58,859 : INFO : training on a 20658150 raw words (17432375 effective words) took 40.3s, 432387 effective words/s\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pvcIZfYaxzc3"
      },
      "source": [
        "## skip-gram 与 CBOW."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k3IW_UukoSPZ",
        "outputId": "fdc2328c-e9d7-44af-d828-8a622859fb18"
      },
      "source": [
        "# sg : {0, 1}, optional Training algorithm: 1 for skip-gram; otherwise CBOW.\n",
        "model = word2vec.Word2Vec(train_data, sg=1,workers=8,min_count=5,size=200,iter=1)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-04-05 06:42:01,998 : INFO : collecting all words and their counts\n",
            "2021-04-05 06:42:02,001 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
            "2021-04-05 06:42:02,055 : INFO : PROGRESS: at sentence #10000, processed 129141 words, keeping 25698 word types\n",
            "2021-04-05 06:42:02,104 : INFO : PROGRESS: at sentence #20000, processed 258779 words, keeping 39123 word types\n",
            "2021-04-05 06:42:02,161 : INFO : PROGRESS: at sentence #30000, processed 387255 words, keeping 49324 word types\n",
            "2021-04-05 06:42:02,209 : INFO : PROGRESS: at sentence #40000, processed 515598 words, keeping 57864 word types\n",
            "2021-04-05 06:42:02,260 : INFO : PROGRESS: at sentence #50000, processed 644895 words, keeping 65382 word types\n",
            "2021-04-05 06:42:02,306 : INFO : PROGRESS: at sentence #60000, processed 774201 words, keeping 67815 word types\n",
            "2021-04-05 06:42:02,352 : INFO : PROGRESS: at sentence #70000, processed 903891 words, keeping 67815 word types\n",
            "2021-04-05 06:42:02,403 : INFO : PROGRESS: at sentence #80000, processed 1032613 words, keeping 67815 word types\n",
            "2021-04-05 06:42:02,450 : INFO : PROGRESS: at sentence #90000, processed 1161529 words, keeping 67815 word types\n",
            "2021-04-05 06:42:02,501 : INFO : PROGRESS: at sentence #100000, processed 1289998 words, keeping 67815 word types\n",
            "2021-04-05 06:42:02,552 : INFO : PROGRESS: at sentence #110000, processed 1419372 words, keeping 67815 word types\n",
            "2021-04-05 06:42:02,605 : INFO : PROGRESS: at sentence #120000, processed 1548930 words, keeping 67815 word types\n",
            "2021-04-05 06:42:02,655 : INFO : PROGRESS: at sentence #130000, processed 1678029 words, keeping 67815 word types\n",
            "2021-04-05 06:42:02,706 : INFO : PROGRESS: at sentence #140000, processed 1807295 words, keeping 67815 word types\n",
            "2021-04-05 06:42:02,756 : INFO : PROGRESS: at sentence #150000, processed 1935386 words, keeping 67815 word types\n",
            "2021-04-05 06:42:02,818 : INFO : PROGRESS: at sentence #160000, processed 2064737 words, keeping 67815 word types\n",
            "2021-04-05 06:42:02,824 : INFO : collected 67815 word types from a corpus of 2065815 raw words and 160080 sentences\n",
            "2021-04-05 06:42:02,825 : INFO : Loading a fresh vocabulary\n",
            "2021-04-05 06:42:03,120 : INFO : effective_min_count=5 retains 31842 unique words (46% of original 67815, drops 35973)\n",
            "2021-04-05 06:42:03,122 : INFO : effective_min_count=5 leaves 1957896 word corpus (94% of original 2065815, drops 107919)\n",
            "2021-04-05 06:42:03,241 : INFO : deleting the raw counts dictionary of 67815 items\n",
            "2021-04-05 06:42:03,244 : INFO : sample=0.001 downsamples 30 most-common words\n",
            "2021-04-05 06:42:03,246 : INFO : downsampling leaves estimated 1627809 word corpus (83.1% of prior 1957896)\n",
            "2021-04-05 06:42:03,368 : INFO : estimated required memory for 31842 words and 200 dimensions: 66868200 bytes\n",
            "2021-04-05 06:42:03,370 : INFO : resetting layer weights\n",
            "2021-04-05 06:42:10,566 : INFO : training model with 8 workers on 31842 vocabulary and 200 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
            "2021-04-05 06:42:11,587 : INFO : EPOCH 1 - PROGRESS: at 19.82% examples, 320524 words/s, in_qsize 14, out_qsize 4\n",
            "2021-04-05 06:42:12,650 : INFO : EPOCH 1 - PROGRESS: at 45.45% examples, 357545 words/s, in_qsize 15, out_qsize 0\n",
            "2021-04-05 06:42:13,682 : INFO : EPOCH 1 - PROGRESS: at 69.19% examples, 362925 words/s, in_qsize 15, out_qsize 0\n",
            "2021-04-05 06:42:14,776 : INFO : EPOCH 1 - PROGRESS: at 93.39% examples, 362173 words/s, in_qsize 13, out_qsize 1\n",
            "2021-04-05 06:42:14,840 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
            "2021-04-05 06:42:14,863 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
            "2021-04-05 06:42:14,871 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
            "2021-04-05 06:42:14,886 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
            "2021-04-05 06:42:14,913 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
            "2021-04-05 06:42:14,936 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2021-04-05 06:42:14,947 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2021-04-05 06:42:14,950 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2021-04-05 06:42:14,951 : INFO : EPOCH - 1 : training on 2065815 raw words (1627554 effective words) took 4.4s, 372282 effective words/s\n",
            "2021-04-05 06:42:14,953 : INFO : training on a 2065815 raw words (1627554 effective words) took 4.4s, 371084 effective words/s\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "83wKQRBxoSPZ"
      },
      "source": [
        "# 查找最近的词"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D-cNkE3foSPa",
        "outputId": "eae0396b-251e-43a1-98ea-cb8b75d37e14"
      },
      "source": [
        "model.wv.most_similar(['智能'],topn=10)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('农业', 0.9993733763694763),\n",
              " ('美铝', 0.9988551139831543),\n",
              " ('科技', 0.9978682994842529),\n",
              " ('电商', 0.9966495037078857),\n",
              " ('零售', 0.9964438676834106),\n",
              " ('物流', 0.9961023330688477),\n",
              " ('鸿润', 0.9958018064498901),\n",
              " ('建设', 0.9957801699638367),\n",
              " ('金融', 0.9954661726951599),\n",
              " ('巴航', 0.9950317740440369)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oUFvr2lUoSPa"
      },
      "source": [
        "# 保存模型"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dmQb8m2RoSPa"
      },
      "source": [
        "save_model_path='word2vec.model'"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wafv8S_WoSPa",
        "outputId": "f9447c4d-b239-4c48-c8d9-24b2f922e7a2"
      },
      "source": [
        "model.save(save_model_path)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-04-05 06:42:58,312 : INFO : saving Word2Vec object under word2vec.model, separately None\n",
            "2021-04-05 06:42:58,314 : INFO : not storing attribute vectors_norm\n",
            "2021-04-05 06:42:58,316 : INFO : not storing attribute cum_table\n",
            "2021-04-05 06:42:58,947 : INFO : saved word2vec.model\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jpBkISEwoSPa"
      },
      "source": [
        "# 载入模型"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4E-tCasCoSPb",
        "outputId": "ade19c7a-1c0e-402d-d188-c1878cbe31c3"
      },
      "source": [
        "model = word2vec.Word2Vec.load(save_model_path)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-04-05 06:43:03,418 : INFO : loading Word2Vec object from word2vec.model\n",
            "2021-04-05 06:43:03,859 : INFO : loading wv recursively from word2vec.model.wv.* with mmap=None\n",
            "2021-04-05 06:43:03,862 : INFO : setting ignored attribute vectors_norm to None\n",
            "2021-04-05 06:43:03,866 : INFO : loading vocabulary recursively from word2vec.model.vocabulary.* with mmap=None\n",
            "2021-04-05 06:43:03,870 : INFO : loading trainables recursively from word2vec.model.trainables.* with mmap=None\n",
            "2021-04-05 06:43:03,876 : INFO : setting ignored attribute cum_table to None\n",
            "2021-04-05 06:43:03,877 : INFO : loaded word2vec.model\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RNuA1D4_oSPb",
        "outputId": "fed496bb-93eb-44ed-ca0a-420dd3edaf35"
      },
      "source": [
        "model.wv.most_similar(['奇瑞'],topn=10)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-04-05 06:43:06,461 : INFO : precomputing L2-norms of word weight vectors\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('公积金', 0.9978774189949036),\n",
              " ('股价', 0.9977446794509888),\n",
              " ('小麦', 0.997087299823761),\n",
              " ('自主', 0.9970433712005615),\n",
              " ('东风', 0.9969918727874756),\n",
              " ('坊', 0.9968271851539612),\n",
              " ('沃尔沃', 0.9967370629310608),\n",
              " ('幼儿园', 0.9965959787368774),\n",
              " ('本田', 0.9965536594390869),\n",
              " ('千亿', 0.9965298771858215)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7TgYynPFoSPb"
      },
      "source": [
        "# 参考"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gl6dGSp3oSPb"
      },
      "source": [
        "1. https://radimrehurek.com/gensim/models/word2vec.html "
      ]
    }
  ]
}